{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dkd99/my-code-practice/blob/main/Spark_create_DataFRAME.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark py4j"
      ],
      "metadata": {
        "id": "oeVdaWnuwozd",
        "outputId": "4e4f4aea-c367-43d4-9abb-a0d2f75f3fd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.0.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.0-py2.py3-none-any.whl size=311317130 sha256=1c00f575f03f46eb09da5fc373c45b203682c6d16eb44f0c075dd20f3c64642f\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/1b/4b/3363a1d04368e7ff0d408e57ff57966fcdf00583774e761327\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n"
      ],
      "metadata": {
        "id": "NpRixJGVwwS6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName(\"Basics\").getOrCreate()\n"
      ],
      "metadata": {
        "id": "SePxOL_Lw0ns"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "help(spark.createDataFrame)"
      ],
      "metadata": {
        "id": "34y-Ye_gxCbk",
        "outputId": "7c1f2954-4940-43b2-c8a0-bd249edf58f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on method createDataFrame in module pyspark.sql.session:\n",
            "\n",
            "createDataFrame(data: Union[pyspark.rdd.RDD[Any], Iterable[Any], ForwardRef('PandasDataFrameLike'), ForwardRef('ArrayLike')], schema: Union[pyspark.sql.types.AtomicType, pyspark.sql.types.StructType, str, NoneType] = None, samplingRatio: Optional[float] = None, verifySchema: bool = True) -> pyspark.sql.dataframe.DataFrame method of pyspark.sql.session.SparkSession instance\n",
            "    Creates a :class:`DataFrame` from an :class:`RDD`, a list, a :class:`pandas.DataFrame`\n",
            "    or a :class:`numpy.ndarray`.\n",
            "    \n",
            "    .. versionadded:: 2.0.0\n",
            "    \n",
            "    .. versionchanged:: 3.4.0\n",
            "        Supports Spark Connect.\n",
            "    \n",
            "    Parameters\n",
            "    ----------\n",
            "    data : :class:`RDD` or iterable\n",
            "        an RDD of any kind of SQL data representation (:class:`Row`,\n",
            "        :class:`tuple`, ``int``, ``boolean``, etc.), or :class:`list`,\n",
            "        :class:`pandas.DataFrame` or :class:`numpy.ndarray`.\n",
            "    schema : :class:`pyspark.sql.types.DataType`, str or list, optional\n",
            "        a :class:`pyspark.sql.types.DataType` or a datatype string or a list of\n",
            "        column names, default is None.  The data type string format equals to\n",
            "        :class:`pyspark.sql.types.DataType.simpleString`, except that top level struct type can\n",
            "        omit the ``struct<>``.\n",
            "    \n",
            "        When ``schema`` is a list of column names, the type of each column\n",
            "        will be inferred from ``data``.\n",
            "    \n",
            "        When ``schema`` is ``None``, it will try to infer the schema (column names and types)\n",
            "        from ``data``, which should be an RDD of either :class:`Row`,\n",
            "        :class:`namedtuple`, or :class:`dict`.\n",
            "    \n",
            "        When ``schema`` is :class:`pyspark.sql.types.DataType` or a datatype string, it must\n",
            "        match the real data, or an exception will be thrown at runtime. If the given schema is\n",
            "        not :class:`pyspark.sql.types.StructType`, it will be wrapped into a\n",
            "        :class:`pyspark.sql.types.StructType` as its only field, and the field name will be\n",
            "        \"value\". Each record will also be wrapped into a tuple, which can be converted to row\n",
            "        later.\n",
            "    samplingRatio : float, optional\n",
            "        the sample ratio of rows used for inferring. The first few rows will be used\n",
            "        if ``samplingRatio`` is ``None``.\n",
            "    verifySchema : bool, optional\n",
            "        verify data types of every row against schema. Enabled by default.\n",
            "    \n",
            "        .. versionadded:: 2.1.0\n",
            "    \n",
            "    Returns\n",
            "    -------\n",
            "    :class:`DataFrame`\n",
            "    \n",
            "    Notes\n",
            "    -----\n",
            "    Usage with `spark.sql.execution.arrow.pyspark.enabled=True` is experimental.\n",
            "    \n",
            "    Examples\n",
            "    --------\n",
            "    Create a DataFrame from a list of tuples.\n",
            "    \n",
            "    >>> spark.createDataFrame([('Alice', 1)]).collect()\n",
            "    [Row(_1='Alice', _2=1)]\n",
            "    >>> spark.createDataFrame([('Alice', 1)], ['name', 'age']).collect()\n",
            "    [Row(name='Alice', age=1)]\n",
            "    \n",
            "    Create a DataFrame from a list of dictionaries\n",
            "    \n",
            "    >>> d = [{'name': 'Alice', 'age': 1}]\n",
            "    >>> spark.createDataFrame(d).collect()\n",
            "    [Row(age=1, name='Alice')]\n",
            "    \n",
            "    Create a DataFrame from an RDD.\n",
            "    \n",
            "    >>> rdd = spark.sparkContext.parallelize([('Alice', 1)])\n",
            "    >>> spark.createDataFrame(rdd).collect()\n",
            "    [Row(_1='Alice', _2=1)]\n",
            "    >>> df = spark.createDataFrame(rdd, ['name', 'age'])\n",
            "    >>> df.collect()\n",
            "    [Row(name='Alice', age=1)]\n",
            "    \n",
            "    Create a DataFrame from Row instances.\n",
            "    \n",
            "    >>> from pyspark.sql import Row\n",
            "    >>> Person = Row('name', 'age')\n",
            "    >>> person = rdd.map(lambda r: Person(*r))\n",
            "    >>> df2 = spark.createDataFrame(person)\n",
            "    >>> df2.collect()\n",
            "    [Row(name='Alice', age=1)]\n",
            "    \n",
            "    Create a DataFrame with the explicit schema specified.\n",
            "    \n",
            "    >>> from pyspark.sql.types import *\n",
            "    >>> schema = StructType([\n",
            "    ...    StructField(\"name\", StringType(), True),\n",
            "    ...    StructField(\"age\", IntegerType(), True)])\n",
            "    >>> df3 = spark.createDataFrame(rdd, schema)\n",
            "    >>> df3.collect()\n",
            "    [Row(name='Alice', age=1)]\n",
            "    \n",
            "    Create a DataFrame from a pandas DataFrame.\n",
            "    \n",
            "    >>> spark.createDataFrame(df.toPandas()).collect()  # doctest: +SKIP\n",
            "    [Row(name='Alice', age=1)]\n",
            "    >>> spark.createDataFrame(pandas.DataFrame([[1, 2]])).collect()  # doctest: +SKIP\n",
            "    [Row(0=1, 1=2)]\n",
            "    \n",
            "    Create  a DataFrame from an RDD with the schema in DDL formatted string.\n",
            "    \n",
            "    >>> spark.createDataFrame(rdd, \"a: string, b: int\").collect()\n",
            "    [Row(a='Alice', b=1)]\n",
            "    >>> rdd = rdd.map(lambda row: row[1])\n",
            "    >>> spark.createDataFrame(rdd, \"int\").collect()\n",
            "    [Row(value=1)]\n",
            "    \n",
            "    When the type is unmatched, it throws an exception.\n",
            "    \n",
            "    >>> spark.createDataFrame(rdd, \"boolean\").collect() # doctest: +IGNORE_EXCEPTION_DETAIL\n",
            "    Traceback (most recent call last):\n",
            "        ...\n",
            "    Py4JJavaError: ...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ages_list=[21,23,18,22,25]"
      ],
      "metadata": {
        "id": "C38J_yDHxLlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(ages_list)"
      ],
      "metadata": {
        "id": "1er7aL_RxjXr",
        "outputId": "3c12b8c8-8213-44b0-e1ee-b4d9a558f40c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.createDataFrame(ages_list)"
      ],
      "metadata": {
        "id": "tRRL4NHUxxDH",
        "outputId": "411f8252-d944-47e3-aa5d-0c1b2f17347f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-92994bb5c015>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mages_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36mcreateDataFrame\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m   1274\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplingRatio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverifySchema\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1275\u001b[0m             )\n\u001b[0;32m-> 1276\u001b[0;31m         return self._create_dataframe(\n\u001b[0m\u001b[1;32m   1277\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplingRatio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverifySchema\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36m_create_dataframe\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m   1316\u001b[0m             \u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstruct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_createFromRDD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplingRatio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1318\u001b[0;31m             \u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstruct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_createFromLocal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1319\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0mjrdd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerDeUtil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoJavaArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_java_object_rdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36m_createFromLocal\u001b[0;34m(self, data, schema)\u001b[0m\n\u001b[1;32m    960\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 962\u001b[0;31m             \u001b[0mstruct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inferSchemaFromList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    963\u001b[0m             \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_converter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstruct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m             \u001b[0mtupled_data\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36m_inferSchemaFromList\u001b[0;34m(self, data, names)\u001b[0m\n\u001b[1;32m    834\u001b[0m         \u001b[0minfer_array_from_first_element\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacyInferArrayTypeFromFirstElement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m         \u001b[0mprefer_timestamp_ntz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_timestamp_ntz_preferred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m         schema = reduce(\n\u001b[0m\u001b[1;32m    837\u001b[0m             \u001b[0m_merge_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m             (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    837\u001b[0m             \u001b[0m_merge_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m             (\n\u001b[0;32m--> 839\u001b[0;31m                 _infer_schema(\n\u001b[0m\u001b[1;32m    840\u001b[0m                     \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m                     \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/types.py\u001b[0m in \u001b[0;36m_infer_schema\u001b[0;34m(row, names, infer_dict_as_struct, infer_array_from_first_element, prefer_timestamp_ntz)\u001b[0m\n\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can not infer schema for type: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m     \u001b[0mfields\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Can not infer schema for type: <class 'int'>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.createDataFrame(ages_list,'int')"
      ],
      "metadata": {
        "id": "UDuz5fI7x3Qi",
        "outputId": "549ed668-9267-44c4-938b-cfbc2d76c95c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[value: int]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import IntegerType"
      ],
      "metadata": {
        "id": "GLsGZ_R0yGgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.createDataFrame(ages_list,IntegerType()).show()"
      ],
      "metadata": {
        "id": "FLyAQwJ1yQpo",
        "outputId": "2c10dcd2-379f-4885-8f96-6b2ec1ae5462",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+\n",
            "|value|\n",
            "+-----+\n",
            "|   21|\n",
            "|   23|\n",
            "|   18|\n",
            "|   22|\n",
            "|   25|\n",
            "+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "names_list=['deepak','prashant','puneet']"
      ],
      "metadata": {
        "id": "FQmezcmBylKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.createDataFrame(names_list,\"string\")"
      ],
      "metadata": {
        "id": "xplRwAV-yt2Z",
        "outputId": "8909fcde-7860-46d7-d1b0-327016ce4936",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[value: string]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StringType"
      ],
      "metadata": {
        "id": "xW1dTELJy_MS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.createDataFrame(names_list,StringType())"
      ],
      "metadata": {
        "id": "ebKirxqCzB27",
        "outputId": "4a5e9e4a-286b-40c0-bac9-ae8584c445e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[value: string]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "age_list=[(21,),(18,),(23,),(41,)]"
      ],
      "metadata": {
        "id": "bz6aogruzII_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.createDataFrame(age_list)"
      ],
      "metadata": {
        "id": "YDj8XZPfzd31",
        "outputId": "a34a8f0c-0d2f-4a7f-dc84-cb98e82ccb80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[_1: bigint]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.createDataFrame(age_list).show()"
      ],
      "metadata": {
        "id": "w1q4p5N8zzKg",
        "outputId": "8e339636-64ad-4850-9408-c4596507b419",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+\n",
            "| _1|\n",
            "+---+\n",
            "| 21|\n",
            "| 18|\n",
            "| 23|\n",
            "| 41|\n",
            "+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.createDataFrame(age_list,\"age int\")"
      ],
      "metadata": {
        "id": "4hjUDKysz_iR",
        "outputId": "875c6ac9-742d-42e1-c689-aebb34a3cb19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[age: int]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "users_list=[(1,'deepak'),(2,'prashant'),(3,'puneet'),(4,'piyush')]"
      ],
      "metadata": {
        "id": "dqFUJtS90dcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.createDataFrame(users_list,\"user_id int,user_name string\")"
      ],
      "metadata": {
        "id": "zklOpS7404UC",
        "outputId": "fb82337c-4d96-4024-f4f5-125ab6221740",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[user_id: int, user_name: string]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.createDataFrame(users_list,\"user_id int,user_name string\").show()"
      ],
      "metadata": {
        "id": "pchtU-0m1KKn",
        "outputId": "5fc86468-4387-4aac-bf7f-4be747d4cd99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------+\n",
            "|user_id|user_name|\n",
            "+-------+---------+\n",
            "|      1|   deepak|\n",
            "|      2| prashant|\n",
            "|      3|   puneet|\n",
            "|      4|   piyush|\n",
            "+-------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=spark.createDataFrame(users_list,\"user_id int,user_name string\")"
      ],
      "metadata": {
        "id": "CcELNSCH1uDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "id": "CaVDy2Ds1v48",
        "outputId": "36bc549a-1bb0-4b0b-e5ce-cbac95c69823",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------+\n",
            "|user_id|user_name|\n",
            "+-------+---------+\n",
            "|      1|   deepak|\n",
            "|      2| prashant|\n",
            "|      3|   puneet|\n",
            "|      4|   piyush|\n",
            "+-------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.collect()"
      ],
      "metadata": {
        "id": "ECvkdP6r11wL",
        "outputId": "90a3c9b2-2b2e-44cb-d7a7-7f98a606bdfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(user_id=1, user_name='deepak'),\n",
              " Row(user_id=2, user_name='prashant'),\n",
              " Row(user_id=3, user_name='puneet'),\n",
              " Row(user_id=4, user_name='piyush')]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.collect()[0]"
      ],
      "metadata": {
        "id": "eLvpXRcl2Wg9",
        "outputId": "5675f67c-83e5-431b-d450-b3b2c4ab6b2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(user_id=1, user_name='deepak')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(df.collect())"
      ],
      "metadata": {
        "id": "0xNbWECe135M",
        "outputId": "07aae44c-3c68-451d-cbc9-7baf1621d2e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import Row"
      ],
      "metadata": {
        "id": "P2hi8glx2DQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "help(Row)"
      ],
      "metadata": {
        "id": "gz3tTGtY2Ket",
        "outputId": "1fb0b14d-de76-4fc8-c023-e55b53cdd15a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on class Row in module pyspark.sql.types:\n",
            "\n",
            "class Row(builtins.tuple)\n",
            " |  Row(*args: Optional[str], **kwargs: Optional[Any]) -> 'Row'\n",
            " |  \n",
            " |  A row in :class:`DataFrame`.\n",
            " |  The fields in it can be accessed:\n",
            " |  \n",
            " |  * like attributes (``row.key``)\n",
            " |  * like dictionary values (``row[key]``)\n",
            " |  \n",
            " |  ``key in row`` will search through row keys.\n",
            " |  \n",
            " |  Row can be used to create a row object by using named arguments.\n",
            " |  It is not allowed to omit a named argument to represent that the value is\n",
            " |  None or missing. This should be explicitly set to None in this case.\n",
            " |  \n",
            " |  .. versionchanged:: 3.0.0\n",
            " |      Rows created from named arguments no longer have\n",
            " |      field names sorted alphabetically and will be ordered in the position as\n",
            " |      entered.\n",
            " |  \n",
            " |  Examples\n",
            " |  --------\n",
            " |  >>> from pyspark.sql import Row\n",
            " |  >>> row = Row(name=\"Alice\", age=11)\n",
            " |  >>> row\n",
            " |  Row(name='Alice', age=11)\n",
            " |  >>> row['name'], row['age']\n",
            " |  ('Alice', 11)\n",
            " |  >>> row.name, row.age\n",
            " |  ('Alice', 11)\n",
            " |  >>> 'name' in row\n",
            " |  True\n",
            " |  >>> 'wrong_key' in row\n",
            " |  False\n",
            " |  \n",
            " |  Row also can be used to create another Row like class, then it\n",
            " |  could be used to create Row objects, such as\n",
            " |  \n",
            " |  >>> Person = Row(\"name\", \"age\")\n",
            " |  >>> Person\n",
            " |  <Row('name', 'age')>\n",
            " |  >>> 'name' in Person\n",
            " |  True\n",
            " |  >>> 'wrong_key' in Person\n",
            " |  False\n",
            " |  >>> Person(\"Alice\", 11)\n",
            " |  Row(name='Alice', age=11)\n",
            " |  \n",
            " |  This form can also be used to create rows as tuple values, i.e. with unnamed\n",
            " |  fields.\n",
            " |  \n",
            " |  >>> row1 = Row(\"Alice\", 11)\n",
            " |  >>> row2 = Row(name=\"Alice\", age=11)\n",
            " |  >>> row1 == row2\n",
            " |  True\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      Row\n",
            " |      builtins.tuple\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __call__(self, *args: Any) -> 'Row'\n",
            " |      create new Row object\n",
            " |  \n",
            " |  __contains__(self, item: Any) -> bool\n",
            " |      Return key in self.\n",
            " |  \n",
            " |  __getattr__(self, item: str) -> Any\n",
            " |  \n",
            " |  __getitem__(self, item: Any) -> Any\n",
            " |      Return self[key].\n",
            " |  \n",
            " |  __reduce__(self) -> Union[str, Tuple[Any, ...]]\n",
            " |      Returns a tuple so Python knows how to pickle Row.\n",
            " |  \n",
            " |  __repr__(self) -> str\n",
            " |      Printable representation of Row used in Python REPL.\n",
            " |  \n",
            " |  __setattr__(self, key: Any, value: Any) -> None\n",
            " |      Implement setattr(self, name, value).\n",
            " |  \n",
            " |  asDict(self, recursive: bool = False) -> Dict[str, Any]\n",
            " |      Return as a dict\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      recursive : bool, optional\n",
            " |          turns the nested Rows to dict (default: False).\n",
            " |      \n",
            " |      Notes\n",
            " |      -----\n",
            " |      If a row contains duplicate field names, e.g., the rows of a join\n",
            " |      between two :class:`DataFrame` that both have the fields of same names,\n",
            " |      one of the duplicate fields will be selected by ``asDict``. ``__getitem__``\n",
            " |      will also return one of the duplicate fields, however returned value might\n",
            " |      be different to ``asDict``.\n",
            " |      \n",
            " |      Examples\n",
            " |      --------\n",
            " |      >>> from pyspark.sql import Row\n",
            " |      >>> Row(name=\"Alice\", age=11).asDict() == {'name': 'Alice', 'age': 11}\n",
            " |      True\n",
            " |      >>> row = Row(key=1, value=Row(name='a', age=2))\n",
            " |      >>> row.asDict() == {'key': 1, 'value': Row(name='a', age=2)}\n",
            " |      True\n",
            " |      >>> row.asDict(True) == {'key': 1, 'value': {'name': 'a', 'age': 2}}\n",
            " |      True\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Static methods defined here:\n",
            " |  \n",
            " |  __new__(cls, *args: Optional[str], **kwargs: Optional[Any]) -> 'Row'\n",
            " |      Create and return a new object.  See help(type) for accurate signature.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors defined here:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from builtins.tuple:\n",
            " |  \n",
            " |  __add__(self, value, /)\n",
            " |      Return self+value.\n",
            " |  \n",
            " |  __eq__(self, value, /)\n",
            " |      Return self==value.\n",
            " |  \n",
            " |  __ge__(self, value, /)\n",
            " |      Return self>=value.\n",
            " |  \n",
            " |  __getattribute__(self, name, /)\n",
            " |      Return getattr(self, name).\n",
            " |  \n",
            " |  __getnewargs__(self, /)\n",
            " |  \n",
            " |  __gt__(self, value, /)\n",
            " |      Return self>value.\n",
            " |  \n",
            " |  __hash__(self, /)\n",
            " |      Return hash(self).\n",
            " |  \n",
            " |  __iter__(self, /)\n",
            " |      Implement iter(self).\n",
            " |  \n",
            " |  __le__(self, value, /)\n",
            " |      Return self<=value.\n",
            " |  \n",
            " |  __len__(self, /)\n",
            " |      Return len(self).\n",
            " |  \n",
            " |  __lt__(self, value, /)\n",
            " |      Return self<value.\n",
            " |  \n",
            " |  __mul__(self, value, /)\n",
            " |      Return self*value.\n",
            " |  \n",
            " |  __ne__(self, value, /)\n",
            " |      Return self!=value.\n",
            " |  \n",
            " |  __rmul__(self, value, /)\n",
            " |      Return value*self.\n",
            " |  \n",
            " |  count(self, value, /)\n",
            " |      Return number of occurrences of value.\n",
            " |  \n",
            " |  index(self, value, start=0, stop=9223372036854775807, /)\n",
            " |      Return first index of value.\n",
            " |      \n",
            " |      Raises ValueError if the value is not present.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods inherited from builtins.tuple:\n",
            " |  \n",
            " |  __class_getitem__(...) from builtins.type\n",
            " |      See PEP 585\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "row=Row(\"Alice\",11)"
      ],
      "metadata": {
        "id": "c5--HZOz3B5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "row"
      ],
      "metadata": {
        "id": "8D2-8CXe3I-n",
        "outputId": "732e4a6a-a785-4f2c-9bed-60039e0a3434",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Row('Alice', 11)>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "row2=Row(name=\"Alice\",age=11)"
      ],
      "metadata": {
        "id": "TEJRnbdV3KPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "row2"
      ],
      "metadata": {
        "id": "DXIoKj4l3RSR",
        "outputId": "3c56eab2-836f-4964-f5db-0d4819f31f8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(name='Alice', age=11)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "row2.name"
      ],
      "metadata": {
        "id": "KK1MKQUx3TxJ",
        "outputId": "1f00fdd2-1876-454e-b344-4e91f7e83e32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Alice'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "users_list=[[1,'deepak'],[2,'prashant'],[3,'puneet'],[4,'piyush']]"
      ],
      "metadata": {
        "id": "2KY5K6F43_Cn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.createDataFrame(users_list)"
      ],
      "metadata": {
        "id": "r_iSqvR94Zda",
        "outputId": "a73e9c12-21e6-4162-a54e-7b5f0e6d1059",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[_1: bigint, _2: string]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.createDataFrame(users_list,\"id int,name string\")"
      ],
      "metadata": {
        "id": "EhSXHNXX4g-q",
        "outputId": "1facee7a-979e-44be-af34-7e2d4bffabce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[id: int, name: string]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_list=spark.createDataFrame(users_list,\"id int,name string\")"
      ],
      "metadata": {
        "id": "CFX5uGuv5TOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=list(map(Row,*users_list))"
      ],
      "metadata": {
        "id": "mSWKEF065FFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "id": "DFTvAA8w50jo",
        "outputId": "a9024f3f-8ec7-40a6-a6e2-2d8d87d575bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<Row(1, 2, 3, 4)>, <Row('deepak', 'prashant', 'puneet', 'piyush')>]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[1]"
      ],
      "metadata": {
        "id": "bONGFOrs53qH",
        "outputId": "bfba1c5d-80c0-445c-f153-2b70d0b1bd38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Row(Column<'name'>)>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(map(str,list(range(1,10))))"
      ],
      "metadata": {
        "id": "0GAnBNfr5fQT",
        "outputId": "71ded912-8338-446b-cd51-0a2e67bde57c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1', '2', '3', '4', '5', '6', '7', '8', '9']"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "users_row=[Row(*user) for user in users_list]"
      ],
      "metadata": {
        "id": "-1LOHtgh5_Oj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_row"
      ],
      "metadata": {
        "id": "OU6oyTCz6Q17",
        "outputId": "174834aa-a27b-4e53-d9ce-4c9dbb93ce0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<Row(1, 'deepak')>,\n",
              " <Row(2, 'prashant')>,\n",
              " <Row(3, 'puneet')>,\n",
              " <Row(4, 'piyush')>]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.createDataFrame(users_row)"
      ],
      "metadata": {
        "id": "1zJmcbr464t_",
        "outputId": "2dfa899c-3a09-4dd0-e9a7-fc553df5a042",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[_1: bigint, _2: string]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.createDataFrame(users_row,\"id int,name string\")"
      ],
      "metadata": {
        "id": "czfZ-2Wz8IJl",
        "outputId": "254bbc08-1a64-4549-abce-d20a1e6904d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[id: int, name: string]"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fun(*arg):\n",
        "  print(arg)\n",
        "  print(len(arg))"
      ],
      "metadata": {
        "id": "K7AkUQea8QXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fun(1)"
      ],
      "metadata": {
        "id": "fpyI4GHB8ZHh",
        "outputId": "a03d9290-37ef-47a1-8021-af2da4c889a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1,)\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fun(1,'deepak')"
      ],
      "metadata": {
        "id": "bmxb40cy8bep",
        "outputId": "60ac9fc9-b1cd-4656-9a7e-f5e9bf451214",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 'deepak')\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fun(*[1,'deepak'])"
      ],
      "metadata": {
        "id": "IKqyGvMi8eZj",
        "outputId": "5cf26a87-6b33-4e06-ad7c-f55d26ab1141",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 'deepak')\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dic_list=[{'id':1,\"name\":'deepak'},{'id':2,\"name\":'prashant'},{'id':3,\"name\":'puneet'},{'id':4,\"name\":'piyush'},]"
      ],
      "metadata": {
        "id": "yl7SlerUA62n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.createDataFrame(dic_list)"
      ],
      "metadata": {
        "id": "6ZEk9EvEBToz",
        "outputId": "c485fadd-e509-4784-8edd-57842dad566c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[id: bigint, name: string]"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.createDataFrame(dic_list).show()"
      ],
      "metadata": {
        "id": "S_KzUtbKBYtu",
        "outputId": "9a97dbb5-eaab-4c6c-a0b7-49ce06b79bea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------+\n",
            "| id|    name|\n",
            "+---+--------+\n",
            "|  1|  deepak|\n",
            "|  2|prashant|\n",
            "|  3|  puneet|\n",
            "|  4|  piyush|\n",
            "+---+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Row(*dic_list[1].values())"
      ],
      "metadata": {
        "id": "VpeMk9xZEYFL",
        "outputId": "d8b3bd7d-a0da-4271-9bc6-d0350893462c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Row(2, 'prashant')>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "users_dic_rows=[Row(*user.values()) for user in dic_list ]"
      ],
      "metadata": {
        "id": "91W7PKiEEe3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_dic_rows"
      ],
      "metadata": {
        "id": "-SA0DOugE1Xg",
        "outputId": "aac8a24b-127b-4d84-af96-c2ba76881437",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<Row(1, 'deepak')>,\n",
              " <Row(2, 'prashant')>,\n",
              " <Row(3, 'puneet')>,\n",
              " <Row(4, 'piyush')>]"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.createDataFrame(users_dic_rows,\"id int,name string\")"
      ],
      "metadata": {
        "id": "rEMbFpicFAHz",
        "outputId": "0cc1a2dd-4211-4e2a-bb7a-6addbe8dec58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[id: int, name: string]"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.createDataFrame(users_dic_rows,\"id int,name string\").show()"
      ],
      "metadata": {
        "id": "rSWecblSFMpl",
        "outputId": "27d6d8bf-afe6-4ec1-cfe4-1021e003ad2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------+\n",
            "| id|    name|\n",
            "+---+--------+\n",
            "|  1|  deepak|\n",
            "|  2|prashant|\n",
            "|  3|  puneet|\n",
            "|  4|  piyush|\n",
            "+---+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[Row(**user) for user in dic_list ]"
      ],
      "metadata": {
        "id": "l8YNAhhLFaT4",
        "outputId": "13a4441b-5481-4791-b7dd-fe040bf27b44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(id=1, name='deepak'),\n",
              " Row(id=2, name='prashant'),\n",
              " Row(id=3, name='puneet'),\n",
              " Row(id=4, name='piyush')]"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.createDataFrame([Row(**user) for user in dic_list ])"
      ],
      "metadata": {
        "id": "6g7No00iFpRu",
        "outputId": "86da8e2d-5557-4d80-8419-772fcc8acdce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[id: bigint, name: string]"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.createDataFrame([Row(**user) for user in dic_list ]).show()"
      ],
      "metadata": {
        "id": "bdg74oDNFutJ",
        "outputId": "115f8774-2b4b-4211-e981-9506a8f13340",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------+\n",
            "| id|    name|\n",
            "+---+--------+\n",
            "|  1|  deepak|\n",
            "|  2|prashant|\n",
            "|  3|  puneet|\n",
            "|  4|  piyush|\n",
            "+---+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fun(**x):\n",
        "  print(x)\n",
        "  print(len(x))\n",
        "  "
      ],
      "metadata": {
        "id": "oEGfphQiG2og"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fun(id=1,name='deepak')"
      ],
      "metadata": {
        "id": "jhTMNUoaHt9A",
        "outputId": "4c9c02c1-dffd-454a-ce0c-9ce5c0b8cd3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 1, 'name': 'deepak'}\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fun(**{'id':1,'name':'deepak'})"
      ],
      "metadata": {
        "id": "OP28q-GnH_xZ",
        "outputId": "ae5b99a9-ded4-41f6-af20-f3360d999947",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 1, 'name': 'deepak'}\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fun(1,'deepak')"
      ],
      "metadata": {
        "id": "xi5JHbtZIU7y",
        "outputId": "b940d257-fd4b-441c-ef41-8175f1e5fb2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-14ff014a4e72>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'deepak'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: fun() takes 0 positional arguments but 2 were given"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=[{'id':1,\"name\":'deepak','course':['Mechanical','Machine learning']},\n",
        "    {'id':2,\"name\":'prashant','course':['CS']}]\n"
      ],
      "metadata": {
        "id": "_pkK5IvAMXtO"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dic_new=spark.createDataFrame(df)"
      ],
      "metadata": {
        "id": "wzIkur5IugMS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dic_new.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5YbS3ObvXrE",
        "outputId": "6bdf2322-2792-48b9-c79e-24a2ef9589ab"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- course: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- id: long (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import explode"
      ],
      "metadata": {
        "id": "BnaE8zzzvfFD"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dic_new.withColumn('courses',explode('course')).drop('course').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GoTJCFBwELX",
        "outputId": "f600dfe2-6ca0-4bb0-9611-1af0a431d9ad"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------+----------------+\n",
            "| id|    name|         courses|\n",
            "+---+--------+----------------+\n",
            "|  1|  deepak|      Mechanical|\n",
            "|  1|  deepak|Machine learning|\n",
            "|  2|prashant|              CS|\n",
            "+---+--------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dic_new.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kYEoHHkw1lt",
        "outputId": "7619bcd2-d46a-41c0-8c96-bbdf6b4e4395"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---+--------+\n",
            "|              course| id|    name|\n",
            "+--------------------+---+--------+\n",
            "|[Mechanical, Mach...|  1|  deepak|\n",
            "|                [CS]|  2|prashant|\n",
            "+--------------------+---+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col"
      ],
      "metadata": {
        "id": "xXoodus10vJ3"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dic_new.select('id',col('course')[0].alias('first_subj'),col('course')[1].alias('sec_subj')).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PJqvmTN0poX",
        "outputId": "7aceece3-ba4b-4530-d14f-b107184e6bdb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------+----------------+\n",
            "| id|first_subj|        sec_subj|\n",
            "+---+----------+----------------+\n",
            "|  1|Mechanical|Machine learning|\n",
            "|  2|        CS|            null|\n",
            "+---+----------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_=[{'id':1,\"name\":'deepak','course':{'first':'Mechanical','second':'Machine learning'}},\n",
        "    {'id':2,\"name\":'prashant','course':{'first':'CS','second':'Mechanical'}}]"
      ],
      "metadata": {
        "id": "NJr8SyET3wiw"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "map_df=spark.createDataFrame(df_)"
      ],
      "metadata": {
        "id": "TE2O8zFS7OCH"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.createDataFrame(df_).show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYWyU9534YVm",
        "outputId": "a8f70db8-c20e-4230-8836-75b27cbf1cdf"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------------+---+--------+\n",
            "|course                                           |id |name    |\n",
            "+-------------------------------------------------+---+--------+\n",
            "|{first -> Mechanical, second -> Machine learning}|1  |deepak  |\n",
            "|{first -> CS, second -> Mechanical}              |2  |prashant|\n",
            "+-------------------------------------------------+---+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "map_df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xue8Gz7N5lTd",
        "outputId": "f5c695cb-3dfe-43af-a637-f8346709f9ab"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- course: map (nullable = true)\n",
            " |    |-- key: string\n",
            " |    |-- value: string (valueContainsNull = true)\n",
            " |-- id: long (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "map_df.select('id',col('course')['first'].alias('first_course'),col('course')['second'].alias('sec_course')).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RO2hLA4K9RXS",
        "outputId": "20c18fc1-2c76-440c-ddb5-4e9f85f1d33f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------------+----------------+\n",
            "| id|first_course|      sec_course|\n",
            "+---+------------+----------------+\n",
            "|  1|  Mechanical|Machine learning|\n",
            "|  2|          CS|      Mechanical|\n",
            "+---+------------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "map_df.select('id',explode('course')).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BxfT5Fr_pTa",
        "outputId": "e9bbb75e-c57d-41ad-873f-aa92c38ac9e8"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+----------------+\n",
            "| id|   key|           value|\n",
            "+---+------+----------------+\n",
            "|  1| first|      Mechanical|\n",
            "|  1|second|Machine learning|\n",
            "|  2| first|              CS|\n",
            "|  2|second|      Mechanical|\n",
            "+---+------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFpGghBtKiKE",
        "outputId": "b672d25b-55e6-421e-f815-6b70dabfa1ed"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=spark.read.csv('/content/drive/MyDrive/csv files/appl_stock.csv',inferSchema=True,header=True)"
      ],
      "metadata": {
        "id": "tkUaOgebLMP5"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLAwYgZLLwP_",
        "outputId": "001a64ed-08f1-4a8f-823a-b705c2895aef"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------------+------------------+------------------+------------------+---------+------------------+\n",
            "|      Date|              Open|              High|               Low|             Close|   Volume|         Adj Close|\n",
            "+----------+------------------+------------------+------------------+------------------+---------+------------------+\n",
            "|2010-01-04|        213.429998|        214.499996|212.38000099999996|        214.009998|123432400|         27.727039|\n",
            "|2010-01-05|        214.599998|        215.589994|        213.249994|        214.379993|150476200|27.774976000000002|\n",
            "|2010-01-06|        214.379993|            215.23|        210.750004|        210.969995|138040000|27.333178000000004|\n",
            "|2010-01-07|            211.75|        212.000006|        209.050005|            210.58|119282800|          27.28265|\n",
            "|2010-01-08|        210.299994|        212.000006|209.06000500000002|211.98000499999998|111902700|         27.464034|\n",
            "|2010-01-11|212.79999700000002|        213.000002|        208.450005|210.11000299999998|115557400|         27.221758|\n",
            "|2010-01-12|209.18999499999998|209.76999500000002|        206.419998|        207.720001|148614900|          26.91211|\n",
            "|2010-01-13|        207.870005|210.92999500000002|        204.099998|        210.650002|151473000|          27.29172|\n",
            "|2010-01-14|210.11000299999998|210.45999700000002|        209.020004|            209.43|108223500|         27.133657|\n",
            "|2010-01-15|210.92999500000002|211.59999700000003|        205.869999|            205.93|148516900|26.680197999999997|\n",
            "|2010-01-19|        208.330002|215.18999900000003|        207.240004|        215.039995|182501900|27.860484999999997|\n",
            "|2010-01-20|        214.910006|        215.549994|        209.500002|            211.73|153038200|         27.431644|\n",
            "|2010-01-21|        212.079994|213.30999599999998|        207.210003|        208.069996|152038600|         26.957455|\n",
            "|2010-01-22|206.78000600000001|        207.499996|            197.16|            197.75|220441900|         25.620401|\n",
            "|2010-01-25|202.51000200000001|        204.699999|        200.190002|        203.070002|266424900|26.309658000000002|\n",
            "|2010-01-26|205.95000100000001|        213.710005|        202.580004|        205.940001|466777500|         26.681494|\n",
            "|2010-01-27|        206.849995|            210.58|        199.530001|        207.880005|430642100|26.932840000000002|\n",
            "|2010-01-28|        204.930004|        205.500004|        198.699995|        199.289995|293375600|25.819922000000002|\n",
            "|2010-01-29|        201.079996|        202.199995|        190.250002|        192.060003|311488100|         24.883208|\n",
            "|2010-02-01|192.36999699999998|             196.0|191.29999899999999|        194.729998|187469100|         25.229131|\n",
            "+----------+------------------+------------------+------------------+------------------+---------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-aSbCwhLztH",
        "outputId": "79d1da35-116e-435b-ca06-d260348844cb"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Date: date (nullable = true)\n",
            " |-- Open: double (nullable = true)\n",
            " |-- High: double (nullable = true)\n",
            " |-- Low: double (nullable = true)\n",
            " |-- Close: double (nullable = true)\n",
            " |-- Volume: integer (nullable = true)\n",
            " |-- Adj Close: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print((df.count(), len(df.columns)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfh083_gL3Lu",
        "outputId": "cca27c80-3435-45b8-8afc-afe85091252a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1762, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQYPFR4LMVj1",
        "outputId": "601fb743-b233-4023-84f6-8d605506b1fd"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(['Open','High']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvFGTFhNM3ui",
        "outputId": "5ffa8a55-b6ab-4554-de8c-0ab9f24f86fa"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+------------------+\n",
            "|              Open|              High|\n",
            "+------------------+------------------+\n",
            "|        213.429998|        214.499996|\n",
            "|        214.599998|        215.589994|\n",
            "|        214.379993|            215.23|\n",
            "|            211.75|        212.000006|\n",
            "|        210.299994|        212.000006|\n",
            "|212.79999700000002|        213.000002|\n",
            "|209.18999499999998|209.76999500000002|\n",
            "|        207.870005|210.92999500000002|\n",
            "|210.11000299999998|210.45999700000002|\n",
            "|210.92999500000002|211.59999700000003|\n",
            "|        208.330002|215.18999900000003|\n",
            "|        214.910006|        215.549994|\n",
            "|        212.079994|213.30999599999998|\n",
            "|206.78000600000001|        207.499996|\n",
            "|202.51000200000001|        204.699999|\n",
            "|205.95000100000001|        213.710005|\n",
            "|        206.849995|            210.58|\n",
            "|        204.930004|        205.500004|\n",
            "|        201.079996|        202.199995|\n",
            "|192.36999699999998|             196.0|\n",
            "+------------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.alias('u').select('u.*').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RG7IFXrWNAij",
        "outputId": "79e8e942-512c-4e7d-c66f-49bf58d43885"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------------+------------------+------------------+------------------+---------+------------------+\n",
            "|      Date|              Open|              High|               Low|             Close|   Volume|         Adj Close|\n",
            "+----------+------------------+------------------+------------------+------------------+---------+------------------+\n",
            "|2010-01-04|        213.429998|        214.499996|212.38000099999996|        214.009998|123432400|         27.727039|\n",
            "|2010-01-05|        214.599998|        215.589994|        213.249994|        214.379993|150476200|27.774976000000002|\n",
            "|2010-01-06|        214.379993|            215.23|        210.750004|        210.969995|138040000|27.333178000000004|\n",
            "|2010-01-07|            211.75|        212.000006|        209.050005|            210.58|119282800|          27.28265|\n",
            "|2010-01-08|        210.299994|        212.000006|209.06000500000002|211.98000499999998|111902700|         27.464034|\n",
            "|2010-01-11|212.79999700000002|        213.000002|        208.450005|210.11000299999998|115557400|         27.221758|\n",
            "|2010-01-12|209.18999499999998|209.76999500000002|        206.419998|        207.720001|148614900|          26.91211|\n",
            "|2010-01-13|        207.870005|210.92999500000002|        204.099998|        210.650002|151473000|          27.29172|\n",
            "|2010-01-14|210.11000299999998|210.45999700000002|        209.020004|            209.43|108223500|         27.133657|\n",
            "|2010-01-15|210.92999500000002|211.59999700000003|        205.869999|            205.93|148516900|26.680197999999997|\n",
            "|2010-01-19|        208.330002|215.18999900000003|        207.240004|        215.039995|182501900|27.860484999999997|\n",
            "|2010-01-20|        214.910006|        215.549994|        209.500002|            211.73|153038200|         27.431644|\n",
            "|2010-01-21|        212.079994|213.30999599999998|        207.210003|        208.069996|152038600|         26.957455|\n",
            "|2010-01-22|206.78000600000001|        207.499996|            197.16|            197.75|220441900|         25.620401|\n",
            "|2010-01-25|202.51000200000001|        204.699999|        200.190002|        203.070002|266424900|26.309658000000002|\n",
            "|2010-01-26|205.95000100000001|        213.710005|        202.580004|        205.940001|466777500|         26.681494|\n",
            "|2010-01-27|        206.849995|            210.58|        199.530001|        207.880005|430642100|26.932840000000002|\n",
            "|2010-01-28|        204.930004|        205.500004|        198.699995|        199.289995|293375600|25.819922000000002|\n",
            "|2010-01-29|        201.079996|        202.199995|        190.250002|        192.060003|311488100|         24.883208|\n",
            "|2010-02-01|192.36999699999998|             196.0|191.29999899999999|        194.729998|187469100|         25.229131|\n",
            "+----------+------------------+------------------+------------------+------------------+---------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.selectExpr('Open','Open*2').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nh6ccGiQUsG4",
        "outputId": "083634dc-4d96-4be8-cd4f-0795ab4ba558"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+------------------+\n",
            "|              Open|        (Open * 2)|\n",
            "+------------------+------------------+\n",
            "|        213.429998|        426.859996|\n",
            "|        214.599998|        429.199996|\n",
            "|        214.379993|        428.759986|\n",
            "|            211.75|             423.5|\n",
            "|        210.299994|        420.599988|\n",
            "|212.79999700000002|425.59999400000004|\n",
            "|209.18999499999998|418.37998999999996|\n",
            "|        207.870005|         415.74001|\n",
            "|210.11000299999998|420.22000599999996|\n",
            "|210.92999500000002|421.85999000000004|\n",
            "|        208.330002|        416.660004|\n",
            "|        214.910006|        429.820012|\n",
            "|        212.079994|        424.159988|\n",
            "|206.78000600000001|413.56001200000003|\n",
            "|202.51000200000001|405.02000400000003|\n",
            "|205.95000100000001|411.90000200000003|\n",
            "|        206.849995|         413.69999|\n",
            "|        204.930004|        409.860008|\n",
            "|        201.079996|        402.159992|\n",
            "|192.36999699999998|384.73999399999997|\n",
            "+------------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col,concat,lit"
      ],
      "metadata": {
        "id": "_wvlF8yFNjfY"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l=[['deepak','dubey'],['prashant','dubey'],['puneet','pandey']]"
      ],
      "metadata": {
        "id": "VZODNgTONijT"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conc_df=spark.createDataFrame(l,'first_name string,second_name string')"
      ],
      "metadata": {
        "id": "ntvBACU_OdHG"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conc_df.select('first_name','second_name',concat(col('first_name'),lit(', '),col('second_name')).alias('full name')).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5Ync9JROwGA",
        "outputId": "dffc97f4-1c03-4faa-b613-fa62fc2f6a04"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------+---------------+\n",
            "|first_name|second_name|      full name|\n",
            "+----------+-----------+---------------+\n",
            "|    deepak|      dubey|  deepak, dubey|\n",
            "|  prashant|      dubey|prashant, dubey|\n",
            "|    puneet|     pandey| puneet, pandey|\n",
            "+----------+-----------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conc_df.selectExpr('first_name','second_name',\"concat(first_name, ', ' ,second_name) AS x\",'first_name||first_name').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBZ4Uv9TS2r5",
        "outputId": "a3c91838-58e0-4c9c-b4f6-96661d2bbb14"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------+---------------+------------------------------+\n",
            "|first_name|second_name|              x|concat(first_name, first_name)|\n",
            "+----------+-----------+---------------+------------------------------+\n",
            "|    deepak|      dubey|  deepak, dubey|                  deepakdeepak|\n",
            "|  prashant|      dubey|prashant, dubey|              prashantprashant|\n",
            "|    puneet|     pandey| puneet, pandey|                  puneetpuneet|\n",
            "+----------+-----------+---------------+------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conc_df.createOrReplaceTempView('conc')"
      ],
      "metadata": {
        "id": "i0QCTl3nVtF8"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"\n",
        "SELECT 'first_name','second_name',\"concat(first_name, ', ' ,second_name) AS x\",'first_name||first_name'\n",
        "FROM conc\n",
        "\"\"\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkflK_NGV-a6",
        "outputId": "98a91ac6-09f4-40d0-9f92-0c0087482ae9"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------+------------------------------------------+----------------------+\n",
            "|first_name|second_name|concat(first_name, ', ' ,second_name) AS x|first_name||first_name|\n",
            "+----------+-----------+------------------------------------------+----------------------+\n",
            "|first_name|second_name|concat(first_name, ', ' ,second_name) AS x|first_name||first_name|\n",
            "|first_name|second_name|concat(first_name, ', ' ,second_name) AS x|first_name||first_name|\n",
            "|first_name|second_name|concat(first_name, ', ' ,second_name) AS x|first_name||first_name|\n",
            "+----------+-----------+------------------------------------------+----------------------+\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}