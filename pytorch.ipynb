{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dkd99/my-code-practice/blob/main/pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "2VS7IyJyFd1x"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Generate some data\n",
        "torch.manual_seed(7) # Set the random seed so things are predictable\n",
        "\n",
        "# Features are 3 random normal variables\n",
        "features = torch.randn((1, 3))\n",
        "print(features)\n",
        "\n",
        "# Define the size of each layer in our network\n",
        "n_input = features.shape[1]     # Number of input units, must match number of input features\n",
        "print(n_input)\n",
        "\n",
        "n_hidden = 2                    # Number of hidden units\n",
        "n_output = 1                    # Number of output units\n",
        "\n",
        "# Weights for inputs to hidden layer\n",
        "W1 = torch.randn(n_input, n_hidden)\n",
        "print(W1)\n",
        "# Weights for hidden layer to output layer\n",
        "W2 = torch.randn(n_hidden, n_output)\n",
        "print(W2)\n",
        "# and bias terms for hidden and output layers\n",
        "B1 = torch.randn((1, n_hidden))\n",
        "B2 = torch.randn((1, n_output))"
      ],
      "metadata": {
        "id": "9tmEq_RUFTg4",
        "outputId": "ceabcfa6-5cd0-427d-d386-038a1deeec51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1468,  0.7861,  0.9468]])\n",
            "3\n",
            "tensor([[-1.1143,  1.6908],\n",
            "        [-0.8948, -0.3556],\n",
            "        [ 1.2324,  0.1382]])\n",
            "tensor([[-1.6822],\n",
            "        [ 0.3177]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary packages\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import helper\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "gqRI9M0gW4Og"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The MNIST datasets are hosted on yann.lecun.com that has moved under CloudFlare protection\n",
        "# Run this script to enable the datasets download\n",
        "# Reference: https://github.com/pytorch/vision/issues/1938\n",
        "\n",
        "from six.moves import urllib\n",
        "opener = urllib.request.build_opener()\n",
        "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
        "urllib.request.install_opener(opener)"
      ],
      "metadata": {
        "id": "Z7chMGtKW8n5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Run this cell\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                              transforms.Normalize((0.5,), (0.5,)),\n",
        "                              ])\n",
        "\n",
        "# Download and load the training data\n",
        "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "h0lcOC9jXBA4",
        "outputId": "d84a53bf-4ec0-4fe3-cd44-34ba4cb52011",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 52350225.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 1678732.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 14349959.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 7180749.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)\n",
        "print(type(images))\n",
        "print(images.shape)\n",
        "print(labels.shape)"
      ],
      "metadata": {
        "id": "m69CWiE7XFNA",
        "outputId": "dddf911b-d6bb-496c-b160-a4f2f04d202e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images[1]"
      ],
      "metadata": {
        "id": "3Kl023UfXKtq",
        "outputId": "fe5100a9-d370-471b-8aaf-073fe7ade562",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -0.7647, -0.2314,  0.2471,  0.6078,  0.9922,\n",
              "           1.0000,  0.9922,  0.9922,  0.4980, -0.2471, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -0.9451,  0.5922,  0.9843,  0.9843,  0.9843,  0.9843,\n",
              "           0.9922,  0.9843,  0.9843,  0.9843,  0.9451,  0.3804, -0.9059,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -0.6235,  0.9843,  0.9843,  0.9686,  0.8275,  0.4431,\n",
              "           0.2549, -0.1765,  0.2000,  0.9294,  0.9843,  0.9843, -0.3882,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -0.8745, -0.0118,  0.1451, -0.4824, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -0.8039,  0.6706,  0.9843,  0.3176,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -0.9843, -0.1294,  0.8667,  0.9843,  0.1765,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -0.8667,  0.3098,  0.9843,  0.9843,  0.8039, -0.8902,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -0.7020, -0.3333, -0.4824, -0.4275, -0.3333,\n",
              "           0.4039,  0.9216,  0.9843,  0.9843,  0.6078, -0.2627, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -0.1137,  0.9843,  0.9686,  0.9686,  0.9843,\n",
              "           0.9922,  0.9843,  0.9843,  0.8510, -0.5843, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -0.1137,  0.9843,  0.9843,  0.9843,  0.9843,\n",
              "           0.9922,  0.9843,  0.9843,  0.4588, -0.9843, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -0.1137,  0.9843,  0.9843,  0.9843,  0.9843,\n",
              "           0.4431,  0.9843,  0.9843,  0.9843,  0.0980, -0.8588, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -0.7255, -0.7255, -1.0000, -0.7255,\n",
              "          -1.0000, -0.6157,  0.3255,  0.9922,  0.9922,  0.2941, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -0.9843, -0.2863,  0.7961,  0.9686, -0.4745,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000,  0.1059,  0.9843, -0.1137,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -0.7804, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000,  0.1059,  0.9843,  0.3176,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -0.8902,  0.7882, -0.1137, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000,  0.1059,  0.9843,  0.3176,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           0.1922,  0.9843,  0.5686, -0.9529, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000,  0.1059,  0.9843,  0.3176,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -0.1922,  0.9843,  0.9843,  0.3255, -0.7255, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -0.3333,  0.7255,  0.9843,  0.0667,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -0.7569,  0.7333,  0.9843,  0.9843,  0.7804,  0.1765, -0.0902,\n",
              "          -0.5529,  0.0980,  0.2078,  0.9608,  0.9843,  0.8902, -0.7569,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -0.0118,  0.5843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
              "           0.9922,  0.9843,  0.9843,  0.9843,  0.9373,  0.0824, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -0.4431,  0.7647,  0.9843,  0.9843,  0.9843,\n",
              "           0.9922,  0.9843,  0.9843,  0.9843,  0.0667, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000]]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r');\n"
      ],
      "metadata": {
        "id": "GiYxevsgZEUC",
        "outputId": "da3907e4-3751-42ad-d47d-44cd1b81d62e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 417,
              "height": 413
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Solution\n",
        "def activation(x):\n",
        "    return 1/(1+torch.exp(-x))\n",
        "\n",
        "# Flatten the input images\n",
        "inputs = images.view(images.shape[0], -1)\n",
        "\n",
        "# Create parameters\n",
        "w1 = torch.randn(784, 256)\n",
        "b1 = torch.randn(256)\n",
        "\n",
        "w2 = torch.randn(256, 10)\n",
        "b2 = torch.randn(10)\n",
        "\n",
        "h = activation(torch.mm(inputs, w1) + b1)\n",
        "\n",
        "out = activation(torch.mm(h, w2) + b2)"
      ],
      "metadata": {
        "id": "i8-eqxxjhBr3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Solution\n",
        "def softmax(x):\n",
        "    return torch.exp(x)/torch.sum(torch.exp(x), dim=1).view(-1, 1)\n",
        "\n",
        "probabilities = softmax(out)\n",
        "\n",
        "# Does it have the right shape? Should be (64, 10)\n",
        "print(probabilities.shape)\n",
        "# Does it sum to 1?\n",
        "print(probabilities.sum(dim=1))"
      ],
      "metadata": {
        "id": "F7eEDDVDhbfQ",
        "outputId": "dd95853b-87b7-408f-f2f6-c0d81109b080",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 10])\n",
            "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(probabilities)"
      ],
      "metadata": {
        "id": "QMG2BxvaheFG",
        "outputId": "fdec6faf-1438-4ff0-c968-d668d8d09d8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0720, 0.0720, 0.0720, 0.0932, 0.0720, 0.1956, 0.0720, 0.1956, 0.0838,\n",
            "         0.0720],\n",
            "        [0.0802, 0.0740, 0.0740, 0.0741, 0.0740, 0.2010, 0.0741, 0.0740, 0.2003,\n",
            "         0.0744],\n",
            "        [0.0857, 0.0839, 0.0839, 0.0840, 0.0840, 0.2282, 0.0844, 0.0840, 0.0923,\n",
            "         0.0895],\n",
            "        [0.0642, 0.0643, 0.0642, 0.1199, 0.0642, 0.1744, 0.1555, 0.0647, 0.1645,\n",
            "         0.0642],\n",
            "        [0.1590, 0.0708, 0.0708, 0.0708, 0.0708, 0.1924, 0.0713, 0.0708, 0.1499,\n",
            "         0.0735],\n",
            "        [0.1355, 0.0679, 0.0679, 0.0679, 0.0679, 0.1826, 0.0914, 0.0715, 0.1795,\n",
            "         0.0679],\n",
            "        [0.0599, 0.1497, 0.0597, 0.0599, 0.0597, 0.1623, 0.1621, 0.0648, 0.1623,\n",
            "         0.0597],\n",
            "        [0.0651, 0.0786, 0.0652, 0.0651, 0.0651, 0.1768, 0.1768, 0.1768, 0.0656,\n",
            "         0.0650],\n",
            "        [0.0751, 0.0725, 0.0725, 0.1200, 0.0725, 0.0732, 0.1790, 0.0796, 0.1832,\n",
            "         0.0725],\n",
            "        [0.0753, 0.0752, 0.0756, 0.0752, 0.0752, 0.2045, 0.0753, 0.0761, 0.1875,\n",
            "         0.0800],\n",
            "        [0.0803, 0.0744, 0.0745, 0.0740, 0.0738, 0.2004, 0.0747, 0.2001, 0.0739,\n",
            "         0.0738],\n",
            "        [0.0747, 0.0731, 0.0731, 0.0731, 0.0731, 0.1987, 0.0894, 0.1986, 0.0732,\n",
            "         0.0731],\n",
            "        [0.0600, 0.0600, 0.0600, 0.0600, 0.0600, 0.1613, 0.1551, 0.1621, 0.1616,\n",
            "         0.0600],\n",
            "        [0.0659, 0.0659, 0.0659, 0.0662, 0.0659, 0.1792, 0.1791, 0.1791, 0.0667,\n",
            "         0.0659],\n",
            "        [0.0985, 0.0639, 0.0639, 0.0643, 0.0643, 0.1736, 0.1700, 0.1735, 0.0641,\n",
            "         0.0639],\n",
            "        [0.0601, 0.0591, 0.0590, 0.0591, 0.0590, 0.1604, 0.1598, 0.1603, 0.1603,\n",
            "         0.0629],\n",
            "        [0.1791, 0.0659, 0.0659, 0.0669, 0.0659, 0.1792, 0.0660, 0.1792, 0.0659,\n",
            "         0.0659],\n",
            "        [0.1396, 0.0583, 0.0579, 0.0579, 0.0585, 0.1575, 0.1343, 0.1347, 0.1434,\n",
            "         0.0580],\n",
            "        [0.0676, 0.0676, 0.0675, 0.0675, 0.1708, 0.1587, 0.0677, 0.0894, 0.1757,\n",
            "         0.0675],\n",
            "        [0.0799, 0.0595, 0.0605, 0.0596, 0.0626, 0.0620, 0.1617, 0.1604, 0.1617,\n",
            "         0.1322],\n",
            "        [0.0839, 0.0838, 0.0840, 0.0838, 0.0838, 0.2278, 0.0844, 0.0939, 0.0906,\n",
            "         0.0838],\n",
            "        [0.0742, 0.0743, 0.0742, 0.1666, 0.0742, 0.2017, 0.0743, 0.0747, 0.1115,\n",
            "         0.0743],\n",
            "        [0.0933, 0.0833, 0.0831, 0.0841, 0.0831, 0.2254, 0.0832, 0.0983, 0.0831,\n",
            "         0.0831],\n",
            "        [0.1562, 0.0592, 0.0592, 0.0593, 0.0592, 0.1609, 0.0712, 0.1570, 0.1586,\n",
            "         0.0592],\n",
            "        [0.0617, 0.0617, 0.0617, 0.1674, 0.0617, 0.1677, 0.1673, 0.1274, 0.0619,\n",
            "         0.0617],\n",
            "        [0.0724, 0.0723, 0.0723, 0.0724, 0.0725, 0.1750, 0.1127, 0.0820, 0.1960,\n",
            "         0.0724],\n",
            "        [0.0914, 0.0718, 0.0718, 0.0718, 0.0718, 0.1951, 0.0875, 0.0729, 0.1944,\n",
            "         0.0718],\n",
            "        [0.0756, 0.0744, 0.0753, 0.0768, 0.0745, 0.2022, 0.0802, 0.1916, 0.0749,\n",
            "         0.0746],\n",
            "        [0.0847, 0.0847, 0.0847, 0.0848, 0.0847, 0.2278, 0.0908, 0.0847, 0.0860,\n",
            "         0.0873],\n",
            "        [0.0667, 0.0658, 0.0658, 0.0658, 0.0658, 0.1780, 0.0735, 0.1738, 0.1785,\n",
            "         0.0663],\n",
            "        [0.0667, 0.0602, 0.0616, 0.0605, 0.0602, 0.1637, 0.0624, 0.1511, 0.1618,\n",
            "         0.1519],\n",
            "        [0.0654, 0.0653, 0.0651, 0.0651, 0.0651, 0.1750, 0.0834, 0.1620, 0.1765,\n",
            "         0.0770],\n",
            "        [0.0721, 0.0721, 0.0721, 0.0721, 0.0721, 0.1837, 0.1959, 0.0723, 0.1156,\n",
            "         0.0721],\n",
            "        [0.1933, 0.0714, 0.0714, 0.0732, 0.0714, 0.1834, 0.1100, 0.0832, 0.0714,\n",
            "         0.0714],\n",
            "        [0.0873, 0.0752, 0.0752, 0.0752, 0.0752, 0.2043, 0.0789, 0.0752, 0.1758,\n",
            "         0.0779],\n",
            "        [0.0689, 0.0689, 0.0689, 0.0689, 0.0689, 0.1318, 0.1826, 0.1851, 0.0871,\n",
            "         0.0689],\n",
            "        [0.0672, 0.0657, 0.0657, 0.0657, 0.0752, 0.1778, 0.0659, 0.1785, 0.1724,\n",
            "         0.0659],\n",
            "        [0.0679, 0.0668, 0.0678, 0.0669, 0.0668, 0.1815, 0.1642, 0.0668, 0.1816,\n",
            "         0.0696],\n",
            "        [0.0670, 0.0669, 0.0720, 0.0669, 0.0669, 0.1818, 0.1624, 0.0669, 0.1820,\n",
            "         0.0672],\n",
            "        [0.0659, 0.0659, 0.0739, 0.0659, 0.0668, 0.1790, 0.0674, 0.1787, 0.1707,\n",
            "         0.0659],\n",
            "        [0.0641, 0.0639, 0.0654, 0.0639, 0.0639, 0.1736, 0.0965, 0.1678, 0.1736,\n",
            "         0.0674],\n",
            "        [0.1064, 0.0672, 0.0668, 0.0668, 0.0668, 0.1367, 0.1801, 0.0668, 0.1757,\n",
            "         0.0668],\n",
            "        [0.0597, 0.0596, 0.0607, 0.0597, 0.1390, 0.1621, 0.1621, 0.1618, 0.0757,\n",
            "         0.0596],\n",
            "        [0.0744, 0.0780, 0.0738, 0.0740, 0.0777, 0.2004, 0.0740, 0.1966, 0.0740,\n",
            "         0.0771],\n",
            "        [0.0602, 0.0602, 0.0602, 0.0602, 0.0602, 0.1632, 0.1637, 0.1483, 0.1635,\n",
            "         0.0602],\n",
            "        [0.0749, 0.0745, 0.0745, 0.0745, 0.0746, 0.2013, 0.0746, 0.2018, 0.0749,\n",
            "         0.0745],\n",
            "        [0.0676, 0.0616, 0.1423, 0.1149, 0.0616, 0.1671, 0.0986, 0.0652, 0.1596,\n",
            "         0.0616],\n",
            "        [0.0808, 0.0808, 0.0808, 0.0808, 0.0808, 0.2195, 0.0834, 0.0809, 0.1315,\n",
            "         0.0808],\n",
            "        [0.0649, 0.0649, 0.0650, 0.0649, 0.0649, 0.1762, 0.1177, 0.1402, 0.1764,\n",
            "         0.0649],\n",
            "        [0.1740, 0.0645, 0.0645, 0.0647, 0.0646, 0.1155, 0.0652, 0.1061, 0.1055,\n",
            "         0.1753],\n",
            "        [0.1163, 0.1042, 0.0671, 0.0671, 0.0672, 0.1824, 0.1824, 0.0672, 0.0790,\n",
            "         0.0671],\n",
            "        [0.0831, 0.0621, 0.0629, 0.0621, 0.0621, 0.1666, 0.1321, 0.1625, 0.1445,\n",
            "         0.0621],\n",
            "        [0.1469, 0.0652, 0.0652, 0.1039, 0.0652, 0.1634, 0.0826, 0.1772, 0.0652,\n",
            "         0.0652],\n",
            "        [0.1801, 0.0668, 0.0692, 0.0668, 0.0668, 0.1796, 0.0677, 0.1690, 0.0672,\n",
            "         0.0668],\n",
            "        [0.0665, 0.0605, 0.0605, 0.0606, 0.0608, 0.1645, 0.1617, 0.0796, 0.1617,\n",
            "         0.1236],\n",
            "        [0.0657, 0.0656, 0.0657, 0.0657, 0.0657, 0.1785, 0.0742, 0.1784, 0.1750,\n",
            "         0.0656],\n",
            "        [0.0602, 0.0601, 0.0610, 0.0601, 0.0601, 0.1634, 0.1629, 0.1607, 0.1513,\n",
            "         0.0601],\n",
            "        [0.0688, 0.0686, 0.0707, 0.0691, 0.0685, 0.1861, 0.1456, 0.1856, 0.0685,\n",
            "         0.0685],\n",
            "        [0.1360, 0.0777, 0.0779, 0.0777, 0.0777, 0.1102, 0.0778, 0.2027, 0.0844,\n",
            "         0.0777],\n",
            "        [0.0663, 0.0662, 0.0661, 0.0661, 0.0661, 0.1718, 0.0742, 0.1775, 0.1797,\n",
            "         0.0661],\n",
            "        [0.1997, 0.0742, 0.0742, 0.0742, 0.0742, 0.1992, 0.0742, 0.0755, 0.0746,\n",
            "         0.0800],\n",
            "        [0.0741, 0.0655, 0.0655, 0.0655, 0.0655, 0.1781, 0.1777, 0.1634, 0.0790,\n",
            "         0.0655],\n",
            "        [0.0693, 0.0696, 0.0691, 0.1504, 0.0691, 0.1878, 0.0692, 0.1772, 0.0692,\n",
            "         0.0691],\n",
            "        [0.0807, 0.0808, 0.0807, 0.0880, 0.0807, 0.2193, 0.0846, 0.1238, 0.0807,\n",
            "         0.0807]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Parent:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "\n",
        "    def greet(self):\n",
        "        print(\"Hello,\", self.name)\n",
        "\n",
        "class Child(Parent):\n",
        "    def __init__(self, name, age):\n",
        "        super().__init__(name)  # Call parent class constructor\n",
        "        self.age = age\n",
        "\n",
        "    def greet(self):\n",
        "        super().greet()  # Call parent class method\n",
        "        print(\"I am\", self.age, \"years old\")\n",
        "\n",
        "# Create an instance of Child class\n",
        "child = Child(\"Alice\", 10)\n",
        "\n",
        "# Call the overridden method in Child class\n",
        "child.greet()\n"
      ],
      "metadata": {
        "id": "YDghZUKynJQ8",
        "outputId": "1a8f453b-6749-4920-d02f-5823469569f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, Alice\n",
            "I am 10 years old\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Inputs to hidden layer linear transformation\n",
        "        self.hidden = nn.Linear(784, 256)\n",
        "        # Output layer, 10 units - one for each digit\n",
        "        self.output = nn.Linear(256, 10)\n",
        "\n",
        "        # Define sigmoid activation and softmax output\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Pass the input tensor through each of our operations\n",
        "        x = self.hidden(x)\n",
        "        x = self.sigmoid(x)\n",
        "        x = self.output(x)\n",
        "        x = self.softmax(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "bZ-UMiMgihBL"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the network and look at its text representation\n",
        "model = Network()\n",
        "model"
      ],
      "metadata": {
        "id": "wptNZrOPiopo",
        "outputId": "d02e96ca-ebcb-46e7-f61b-64ecb030ad27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Network(\n",
              "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
              "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              "  (softmax): Softmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Inputs to hidden layer linear transformation\n",
        "        self.hidden = nn.Linear(784, 256)\n",
        "        # Output layer, 10 units - one for each digit\n",
        "        self.output = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Hidden layer with sigmoid activation\n",
        "        x = F.sigmoid(self.hidden(x))\n",
        "        # Output layer with softmax activation\n",
        "        x = F.softmax(self.output(x), dim=1)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "ernB5NONkD0B"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Defining the layers, 128, 64, 10 units each\n",
        "        self.fc1 = nn.Linear(784, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        # Output layer, 10 units - one for each digit\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        ''' Forward pass through the network, returns the output logits '''\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        x = F.softmax(x, dim=1)\n",
        "\n",
        "        return x\n",
        "\n",
        "model = Network()\n",
        "model"
      ],
      "metadata": {
        "id": "yrBDK02WkK1l",
        "outputId": "25072ce0-a181-4f88-def9-60b258422161",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Network(\n",
              "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.fc1.weight)\n",
        "print(model.fc1.bias)"
      ],
      "metadata": {
        "id": "bdzkr9w5kTXp",
        "outputId": "b9de94f7-601a-46a3-c24a-327888e7c9f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.0303,  0.0047, -0.0060,  ...,  0.0235,  0.0012, -0.0335],\n",
            "        [ 0.0141,  0.0220,  0.0141,  ..., -0.0081,  0.0335, -0.0211],\n",
            "        [-0.0301, -0.0065,  0.0150,  ...,  0.0091, -0.0224, -0.0060],\n",
            "        ...,\n",
            "        [ 0.0126,  0.0191,  0.0257,  ..., -0.0219,  0.0255, -0.0272],\n",
            "        [ 0.0334, -0.0019, -0.0155,  ..., -0.0205,  0.0314, -0.0051],\n",
            "        [-0.0152,  0.0289,  0.0296,  ..., -0.0032,  0.0309,  0.0017]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.0203, -0.0101,  0.0036, -0.0251, -0.0256, -0.0087,  0.0092, -0.0355,\n",
            "         0.0127, -0.0146, -0.0254, -0.0126, -0.0269,  0.0212,  0.0112, -0.0237,\n",
            "         0.0278,  0.0016, -0.0003,  0.0029, -0.0072,  0.0156,  0.0173, -0.0053,\n",
            "         0.0148,  0.0055,  0.0167, -0.0079,  0.0071,  0.0239,  0.0309,  0.0081,\n",
            "         0.0260,  0.0178, -0.0177,  0.0286, -0.0192,  0.0316, -0.0331, -0.0061,\n",
            "        -0.0203, -0.0219,  0.0069, -0.0191,  0.0133, -0.0211,  0.0017,  0.0135,\n",
            "        -0.0236, -0.0094,  0.0270,  0.0357, -0.0104,  0.0139,  0.0025, -0.0290,\n",
            "         0.0053, -0.0285,  0.0193, -0.0171,  0.0198,  0.0064,  0.0045,  0.0033,\n",
            "        -0.0205, -0.0122,  0.0348, -0.0299, -0.0246,  0.0097, -0.0101, -0.0285,\n",
            "         0.0185,  0.0236,  0.0244, -0.0269, -0.0338, -0.0353,  0.0282,  0.0088,\n",
            "        -0.0025, -0.0083, -0.0050,  0.0320, -0.0272, -0.0181,  0.0189,  0.0148,\n",
            "        -0.0171, -0.0174, -0.0209, -0.0208, -0.0314, -0.0042, -0.0348, -0.0181,\n",
            "         0.0190, -0.0095, -0.0222, -0.0178, -0.0203,  0.0185,  0.0187,  0.0090,\n",
            "        -0.0006,  0.0076,  0.0315,  0.0056, -0.0163, -0.0264,  0.0211,  0.0257,\n",
            "        -0.0102,  0.0162, -0.0246, -0.0264, -0.0353,  0.0094,  0.0132,  0.0222,\n",
            "         0.0061, -0.0267,  0.0225,  0.0054,  0.0100,  0.0295,  0.0133, -0.0244],\n",
            "       requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fc1.bias.data.fill_(0)\n"
      ],
      "metadata": {
        "id": "Gy2S4v0IkXnK",
        "outputId": "b505a5e0-3cb5-41ca-921b-97da76ff2fb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sample from random normal with standard dev = 0.01\n",
        "model.fc1.weight.data.normal_(std=0.01)"
      ],
      "metadata": {
        "id": "yKc-JT12kcMP",
        "outputId": "12e80f9a-55ba-4f45-cb32-103184abe13f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0044,  0.0075, -0.0091,  ..., -0.0029, -0.0191, -0.0109],\n",
              "        [-0.0039,  0.0115,  0.0018,  ...,  0.0032, -0.0116,  0.0238],\n",
              "        [ 0.0001, -0.0048, -0.0022,  ..., -0.0073,  0.0073, -0.0150],\n",
              "        ...,\n",
              "        [ 0.0003, -0.0006,  0.0089,  ..., -0.0065,  0.0105, -0.0093],\n",
              "        [ 0.0069, -0.0074,  0.0049,  ..., -0.0027,  0.0132,  0.0289],\n",
              "        [ 0.0017,  0.0128, -0.0048,  ..., -0.0103, -0.0042, -0.0028]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a random 1x28x28 array\n",
        "array = np.random.rand(1, 28, 28)\n",
        "\n",
        "# Plot the array as an image\n",
        "plt.imshow(array[0], cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "r8_9Ol0UZObA",
        "outputId": "9690765b-e06f-42e8-9f38-d49400b662ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Create a NumPy array of size 4x3x2 filled with zeros\n",
        "array = np.zeros((4, 3, 2))\n",
        "\n",
        "print(\"Shape of the array:\", array.shape)\n",
        "print(\"Array:\")\n",
        "print(array)\n"
      ],
      "metadata": {
        "id": "xFlHHOKKcrbU",
        "outputId": "628d55c3-8711-4cf0-dad1-36f6e360d43c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the array: (4, 3, 2)\n",
            "Array:\n",
            "[[[0. 0.]\n",
            "  [0. 0.]\n",
            "  [0. 0.]]\n",
            "\n",
            " [[0. 0.]\n",
            "  [0. 0.]\n",
            "  [0. 0.]]\n",
            "\n",
            " [[0. 0.]\n",
            "  [0. 0.]\n",
            "  [0. 0.]]\n",
            "\n",
            " [[0. 0.]\n",
            "  [0. 0.]\n",
            "  [0. 0.]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters for our network\n",
        "input_size = 784\n",
        "hidden_sizes = [128, 64]\n",
        "output_size = 10\n",
        "\n",
        "# Build a feed-forward network\n",
        "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_sizes[1], output_size),\n",
        "                      nn.Softmax(dim=1))\n",
        "print(model)\n",
        "\n",
        "# Forward pass through the network and display output\n",
        "images, labels = next(iter(trainloader))\n",
        "images.resize_(images.shape[0], 1, 784)\n",
        "ps = model.forward(images[0,:])\n",
        "helper.view_classify(images[0].view(1, 28, 28), ps)"
      ],
      "metadata": {
        "id": "8vtdVUmbhzQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters for our network\n",
        "input_size = 784\n",
        "hidden_sizes = [128, 64]\n",
        "output_size = 10\n",
        "\n",
        "# Build a feed-forward network\n",
        "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_sizes[1], output_size),\n",
        "                      nn.Softmax(dim=1))\n",
        "print(model)\n",
        "\n",
        "# Forward pass through the network and display output\n",
        "images, labels = next(iter(trainloader))\n",
        "images.resize_(images.shape[0], 1, 784)\n",
        "ps = model.forward(images[0,:])\n",
        "helper.view_classify(images[0].view(1, 28, 28), ps)"
      ],
      "metadata": {
        "id": "bhEe7vthk3wy",
        "outputId": "04863848-d194-43db-d17d-6ea9d0deb68b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (3): ReLU()\n",
            "  (4): Linear(in_features=64, out_features=10, bias=True)\n",
            "  (5): Softmax(dim=1)\n",
            ")\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'helper' has no attribute 'view_classify'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-2efaf9529135>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m784\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mhelper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_classify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: module 'helper' has no attribute 'view_classify'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The MNIST datasets are hosted on yann.lecun.com that has moved under CloudFlare protection\n",
        "# Run this script to enable the datasets download\n",
        "# Reference: https://github.com/pytorch/vision/issues/1938\n",
        "\n",
        "from six.moves import urllib\n",
        "opener = urllib.request.build_opener()\n",
        "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
        "urllib.request.install_opener(opener)"
      ],
      "metadata": {
        "id": "0aZ_NlBa_2S-"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,), (0.5,)),\n",
        "                              ])\n",
        "# Download and load the training data\n",
        "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "gjNjZBPu_94Y"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a feed-forward network\n",
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10))\n",
        "\n",
        "# Define the loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Get our data\n",
        "dataiter = iter(trainloader)\n",
        "\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# Flatten images\n",
        "images = images.view(images.shape[0], -1)\n",
        "\n",
        "# Forward pass, get our logits\n",
        "logits = model(images)\n",
        "# Calculate the loss with the logits and the labels\n",
        "loss = criterion(logits, labels)\n",
        "\n",
        "print(loss)"
      ],
      "metadata": {
        "id": "Lsb3D6k0ADvU",
        "outputId": "bf608247-f30c-4e14-f1f3-f2c685c2fac6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.2966, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import optim\n",
        "\n",
        "# Optimizers require the parameters to optimize and a learning rate\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "jNJpabPsTeec"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
        "\n",
        "epochs = 5\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in trainloader:\n",
        "        # Flatten MNIST images into a 784 long vector\n",
        "        images = images.view(images.shape[0], -1)\n",
        "\n",
        "        # TODO: Training pass\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(images)\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
      ],
      "metadata": {
        "id": "l4h9Q84dTVMp",
        "outputId": "3abf65c8-87c5-4321-f008-843d05d8253d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 1.9400520999548532\n",
            "Training loss: 0.8874037231781335\n",
            "Training loss: 0.5317959228494783\n",
            "Training loss: 0.4323979470013047\n",
            "Training loss: 0.3868062428192798\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Initial weights - ', model[0].weight)\n",
        "\n",
        "images, labels = next(iter(trainloader))\n",
        "images.resize_(64, 784)\n",
        "\n",
        "# Clear the gradients, do this because gradients are accumulated\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# Forward pass, then backward pass, then update weights\n",
        "output = model(images)\n",
        "loss = criterion(output, labels)\n",
        "loss.backward()\n",
        "print('Gradient -', model[0].weight.grad)"
      ],
      "metadata": {
        "id": "-H_ZQ-K5T6FE",
        "outputId": "53e91ab4-ccf9-4c9b-b614-26703d5e3e55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial weights -  Parameter containing:\n",
            "tensor([[ 0.0001, -0.0288, -0.0062,  ..., -0.0169, -0.0017,  0.0285],\n",
            "        [ 0.0041,  0.0040, -0.0233,  ..., -0.0181, -0.0032, -0.0031],\n",
            "        [ 0.0282, -0.0175, -0.0279,  ..., -0.0106, -0.0027, -0.0061],\n",
            "        ...,\n",
            "        [ 0.0093, -0.0050, -0.0328,  ..., -0.0369, -0.0248,  0.0100],\n",
            "        [-0.0066,  0.0038,  0.0043,  ..., -0.0018,  0.0162,  0.0239],\n",
            "        [-0.0136, -0.0143,  0.0085,  ..., -0.0325, -0.0045,  0.0330]],\n",
            "       requires_grad=True)\n",
            "Gradient - tensor([[ 0.0027,  0.0027,  0.0027,  ...,  0.0027,  0.0027,  0.0027],\n",
            "        [ 0.0024,  0.0024,  0.0024,  ...,  0.0024,  0.0024,  0.0024],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        ...,\n",
            "        [-0.0071, -0.0071, -0.0071,  ..., -0.0071, -0.0071, -0.0071],\n",
            "        [-0.0049, -0.0049, -0.0049,  ..., -0.0049, -0.0049, -0.0049],\n",
            "        [ 0.0073,  0.0073,  0.0073,  ...,  0.0073,  0.0073,  0.0073]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Take an update step and few the new weights\n",
        "optimizer.step()\n",
        "print('Updated weights - ', model[0].weight)"
      ],
      "metadata": {
        "id": "1nujOBWtT-oL",
        "outputId": "9d6afac6-4ef3-4909-8edb-c36d572a21e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated weights -  Parameter containing:\n",
            "tensor([[ 9.4071e-05, -2.8840e-02, -6.1946e-03,  ..., -1.6863e-02,\n",
            "         -1.7512e-03,  2.8479e-02],\n",
            "        [ 4.1412e-03,  4.0395e-03, -2.3282e-02,  ..., -1.8108e-02,\n",
            "         -3.1764e-03, -3.1053e-03],\n",
            "        [ 2.8208e-02, -1.7469e-02, -2.7925e-02,  ..., -1.0593e-02,\n",
            "         -2.6703e-03, -6.0650e-03],\n",
            "        ...,\n",
            "        [ 9.3706e-03, -5.0282e-03, -3.2774e-02,  ..., -3.6886e-02,\n",
            "         -2.4774e-02,  1.0050e-02],\n",
            "        [-6.6031e-03,  3.7772e-03,  4.2851e-03,  ..., -1.7616e-03,\n",
            "          1.6222e-02,  2.3887e-02],\n",
            "        [-1.3644e-02, -1.4296e-02,  8.4485e-03,  ..., -3.2509e-02,\n",
            "         -4.5189e-03,  3.2969e-02]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import helper\n",
        "\n",
        "images, labels = next(iter(trainloader))\n",
        "\n",
        "img = images[0].view(1, 784)\n",
        "# Turn off gradients to speed up this part\n",
        "with torch.no_grad():\n",
        "    logps = model(img)\n",
        "\n",
        "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
        "ps = torch.exp(logps)\n",
        "#helper.view_classify(img.view(1, 28, 28), ps)"
      ],
      "metadata": {
        "id": "QJjSwWpGUFCr"
      },
      "execution_count": 34,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}